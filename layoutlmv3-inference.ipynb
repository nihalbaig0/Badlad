{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install Detectron2\n","metadata":{}},{"cell_type":"code","source":"%%capture\nimport sys, os, distutils.core\n# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n!git clone 'https://github.com/facebookresearch/detectron2'\ndist = distutils.core.run_setup(\"./detectron2/setup.py\")\n!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\nsys.path.insert(0, os.path.abspath('./detectron2'))","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:14:45.106104Z","iopub.execute_input":"2023-08-06T15:14:45.106458Z","iopub.status.idle":"2023-08-06T15:15:36.064263Z","shell.execute_reply.started":"2023-08-06T15:14:45.106426Z","shell.execute_reply":"2023-08-06T15:15:36.062716Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Import Libraries\n","metadata":{}},{"cell_type":"code","source":"from detectron2.utils.memory import retry_if_cuda_oom\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.checkpoint import DetectionCheckpointer\nfrom detectron2.modeling import build_model\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nimport detectron2.data.transforms as T\nfrom detectron2.data import detection_utils as utils\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader, DatasetMapper\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.structures import BoxMode\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2 import model_zoo\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm  # progress bar\nimport matplotlib.pyplot as plt\nimport json\nimport cv2\nimport copy\nfrom typing import Optional\n\nfrom IPython.display import FileLink\nimport sys\n# torch\nimport torch\n\nimport gc\n\nimport warnings\n# Ignore \"future\" warnings and Data-Frame-Slicing warnings.\nwarnings.filterwarnings('ignore')\n\nsetup_logger()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:15:36.067456Z","iopub.execute_input":"2023-08-06T15:15:36.069654Z","iopub.status.idle":"2023-08-06T15:15:37.025495Z","shell.execute_reply.started":"2023-08-06T15:15:36.069597Z","shell.execute_reply":"2023-08-06T15:15:37.024513Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<_Logger detectron2 (DEBUG)>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Downloading unilm\n","metadata":{}},{"cell_type":"code","source":"#better to use gdown \n!pip install gdown\n!gdown 1KQTZ6mXstpckzAix3k3XPtY-iEdqyeKD","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:17:56.009068Z","iopub.execute_input":"2023-08-06T15:17:56.009484Z","iopub.status.idle":"2023-08-06T15:18:10.859625Z","shell.execute_reply.started":"2023-08-06T15:17:56.009449Z","shell.execute_reply":"2023-08-06T15:18:10.858352Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Using cached gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.65.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1KQTZ6mXstpckzAix3k3XPtY-iEdqyeKD\nFrom (redirected): https://drive.google.com/uc?id=1KQTZ6mXstpckzAix3k3XPtY-iEdqyeKD&confirm=t&uuid=00b595b6-3e33-48f9-8c9e-b42ab9b7778c\nTo: /kaggle/working/unilm.zip\n100%|█████████████████████████████████████████| 108M/108M [00:00<00:00, 167MB/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Unzipping unilm\n","metadata":{}},{"cell_type":"code","source":"# Replace '/kaggle/working/unilm.zip' with the actual path to your 'unilm.zip' file\nzip_file_path = '/kaggle/working/unilm.zip'\n\n# Replace 'unilm' with the name of the folder where you want to unzip the contents\noutput_folder = 'unilm'\n\n\n# Unzip the file\n!unzip $zip_file_path -d $output_folder","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:18:31.597910Z","iopub.execute_input":"2023-08-06T15:18:31.598359Z","iopub.status.idle":"2023-08-06T15:18:31.604396Z","shell.execute_reply.started":"2023-08-06T15:18:31.598319Z","shell.execute_reply":"2023-08-06T15:18:31.603430Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Setting Path\n","metadata":{}},{"cell_type":"code","source":"sys.path.insert(1, \"/kaggle/working/unilm/layoutlmv3\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:18:53.882884Z","iopub.execute_input":"2023-08-06T15:18:53.883255Z","iopub.status.idle":"2023-08-06T15:18:53.887894Z","shell.execute_reply.started":"2023-08-06T15:18:53.883225Z","shell.execute_reply":"2023-08-06T15:18:53.886961Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"! sed -i 's/from collections import Iterable/from collections.abc import Iterable/' /kaggle/working/unilm/layoutlmv3/examples/object_detection/ditod/table_evaluation/data_structure.py\n","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:04.927253Z","iopub.execute_input":"2023-08-06T15:19:04.927644Z","iopub.status.idle":"2023-08-06T15:19:05.900332Z","shell.execute_reply.started":"2023-08-06T15:19:04.927594Z","shell.execute_reply":"2023-08-06T15:19:05.898922Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Importing vit config\n","metadata":{}},{"cell_type":"code","source":"from examples.object_detection.ditod import add_vit_config\n","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:11.473510Z","iopub.execute_input":"2023-08-06T15:19:11.474471Z","iopub.status.idle":"2023-08-06T15:19:20.442243Z","shell.execute_reply.started":"2023-08-06T15:19:11.474432Z","shell.execute_reply":"2023-08-06T15:19:20.441294Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# cfg = get_cfg()\n# # Add PointRend-specific config\n# add_vit_config(cfg)\n# # Load a config from file\n# cfg.merge_from_file(\"unilm/layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml\")\n# print(cfg)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:29.596857Z","iopub.execute_input":"2023-08-06T15:19:29.597220Z","iopub.status.idle":"2023-08-06T15:19:29.601915Z","shell.execute_reply.started":"2023-08-06T15:19:29.597191Z","shell.execute_reply":"2023-08-06T15:19:29.600898Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Setting Condition\n","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\n\n# if False, model is set to `PRETRAINED_PATH` model\nis_train = True\n\n# if True, evaluate on validation dataset\nis_evaluate = False\n\n# if True, run inference on test dataset\nis_inference = True\n\n# if True and `is_train` == True, `PRETRAINED_PATH` model is trained further\nis_resume_training = False\n\n# Perform augmentation\nis_augment = False\n\nSEED = 42","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:43.891644Z","iopub.execute_input":"2023-08-06T15:19:43.892020Z","iopub.status.idle":"2023-08-06T15:19:43.898261Z","shell.execute_reply.started":"2023-08-06T15:19:43.891989Z","shell.execute_reply":"2023-08-06T15:19:43.896445Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Defining Path\n","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\n\n\nTEST_IMG_DIR = Path(\"/kaggle/input/dlsprint2/badlad/images/test\")\n\nTEST_METADATA_PATH = Path(\"/kaggle/input/dlsprint2/badlad/badlad-test-metadata.json\")\n\n# Training output directory\nOUTPUT_DIR = Path(\"./output\")\nOUTPUT_MODEL = OUTPUT_DIR/\"model_final.pth\"\n\n# Path to your pretrained model weights\nPRETRAINED_PATH = Path(\"\")","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:47.209950Z","iopub.execute_input":"2023-08-06T15:19:47.210653Z","iopub.status.idle":"2023-08-06T15:19:47.216564Z","shell.execute_reply.started":"2023-08-06T15:19:47.210592Z","shell.execute_reply":"2023-08-06T15:19:47.215423Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## JSON Load\n","metadata":{}},{"cell_type":"code","source":"with TEST_METADATA_PATH.open() as f:\n    test_dict = json.load(f)\n\nprint(\"#### LABELS AND METADATA LOADED ####\")","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:51.139716Z","iopub.execute_input":"2023-08-06T15:19:51.140660Z","iopub.status.idle":"2023-08-06T15:19:51.208735Z","shell.execute_reply.started":"2023-08-06T15:19:51.140600Z","shell.execute_reply":"2023-08-06T15:19:51.207755Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"#### LABELS AND METADATA LOADED ####\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Organizing COCO\n","metadata":{}},{"cell_type":"code","source":"def organize_coco_data(data_dict: dict) -> tuple[list[str], list[dict], list[dict]]:\n    thing_classes: list[str] = []\n\n    # Map Category Names to IDs\n    for cat in data_dict['categories']:\n        thing_classes.append(cat['name'])\n\n    # Images\n    images_metadata: list[dict] = data_dict['images']\n\n    # Convert COCO annotations to detectron2 annotations format\n    data_annotations = []\n    for ann in data_dict['annotations']:\n        # coco format -> detectron2 format\n        annot_obj = {\n            # Annotation ID\n            \"id\": ann['id'],\n\n            # Segmentation Polygon (x, y) coords\n            \"gt_masks\": ann['segmentation'],\n\n            # Image ID for this annotation (Which image does this annotation belong to?)\n            \"image_id\": ann['image_id'],\n\n            # Category Label (0: paragraph, 1: text box, 2: image, 3: table)\n            \"category_id\": ann['category_id'],\n\n            \"x_min\": ann['bbox'][0],  # left\n            \"y_min\": ann['bbox'][1],  # top\n            \"x_max\": ann['bbox'][0] + ann['bbox'][2],  # left+width\n            \"y_max\": ann['bbox'][1] + ann['bbox'][3]  # top+height\n        }\n        data_annotations.append(annot_obj)\n\n    return thing_classes, images_metadata, data_annotations","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:52.827283Z","iopub.execute_input":"2023-08-06T15:19:52.827693Z","iopub.status.idle":"2023-08-06T15:19:52.836290Z","shell.execute_reply.started":"2023-08-06T15:19:52.827661Z","shell.execute_reply":"2023-08-06T15:19:52.835086Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"thing_classes_test, images_metadata_test, _ = organize_coco_data(\n    test_dict\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:54.266557Z","iopub.execute_input":"2023-08-06T15:19:54.267331Z","iopub.status.idle":"2023-08-06T15:19:54.272309Z","shell.execute_reply.started":"2023-08-06T15:19:54.267292Z","shell.execute_reply":"2023-08-06T15:19:54.271165Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"test_metadata = pd.DataFrame(images_metadata_test)\ntest_metadata = test_metadata[['id', 'file_name', 'width', 'height']]\ntest_metadata = test_metadata.rename(columns={\"id\": \"image_id\"})\nprint(\"test_metadata size=\", len(test_metadata))\ntest_metadata.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:54.522196Z","iopub.execute_input":"2023-08-06T15:19:54.522564Z","iopub.status.idle":"2023-08-06T15:19:54.587440Z","shell.execute_reply.started":"2023-08-06T15:19:54.522534Z","shell.execute_reply":"2023-08-06T15:19:54.586413Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"test_metadata size= 13000\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"   image_id                                 file_name  width  height\n0         0  96eee398-1275-4768-be89-ec945e6c8bb0.png    720    1018\n1         1  9b77c241-8292-4133-ab7a-0398a99f30a8.png    720    1019\n2         2  3a6ac54b-d3f6-4783-9f71-b6ae29c93f7d.png    720    1105\n3         3  2d0e29cd-83cb-4426-9663-1368c1975c37.png   1080    1920\n4         4  f8c22a4a-6c89-4179-8845-12405bfd0035.png   1080    1920","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>file_name</th>\n      <th>width</th>\n      <th>height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>96eee398-1275-4768-be89-ec945e6c8bb0.png</td>\n      <td>720</td>\n      <td>1018</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>9b77c241-8292-4133-ab7a-0398a99f30a8.png</td>\n      <td>720</td>\n      <td>1019</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3a6ac54b-d3f6-4783-9f71-b6ae29c93f7d.png</td>\n      <td>720</td>\n      <td>1105</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2d0e29cd-83cb-4426-9663-1368c1975c37.png</td>\n      <td>1080</td>\n      <td>1920</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>f8c22a4a-6c89-4179-8845-12405bfd0035.png</td>\n      <td>1080</td>\n      <td>1920</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Registering Data\n","metadata":{}},{"cell_type":"code","source":"DATA_REGISTER_TEST     = \"badlad_test\"\n","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:55.576747Z","iopub.execute_input":"2023-08-06T15:19:55.577100Z","iopub.status.idle":"2023-08-06T15:19:55.581784Z","shell.execute_reply.started":"2023-08-06T15:19:55.577073Z","shell.execute_reply":"2023-08-06T15:19:55.580671Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Detectron2 Format","metadata":{}},{"cell_type":"code","source":"def convert_coco_to_detectron2_format(\n    imgdir: Path,\n    metadata_df: pd.DataFrame,\n    annot_df: Optional[pd.DataFrame] = None,\n    target_indices: Optional[np.ndarray] = None,\n):\n\n    dataset_dicts = []\n    for _, train_meta_row in tqdm(metadata_df.iterrows(), total=len(metadata_df)):\n        # Iterate over each image\n        image_id, filename, width, height = train_meta_row.values\n\n        annotations = []\n\n        # If train/validation data, then there will be annotations\n        if annot_df is not None:\n            for _, ann in annot_df.query(\"image_id == @image_id\").iterrows():\n                # Get annotations of current iteration's image\n                class_id = ann[\"category_id\"]\n                gt_masks = ann[\"gt_masks\"]\n                bbox_resized = [\n                    float(ann[\"x_min\"]),\n                    float(ann[\"y_min\"]),\n                    float(ann[\"x_max\"]),\n                    float(ann[\"y_max\"]),\n                ]\n\n                annotation = {\n                    \"bbox\": bbox_resized,\n                    \"bbox_mode\": BoxMode.XYXY_ABS,\n                    \"segmentation\": gt_masks,\n                    \"category_id\": class_id,\n                }\n\n                annotations.append(annotation)\n\n        # coco format -> detectron2 format dict\n        record = {\n            \"file_name\": str(imgdir/filename),\n            \"image_id\": image_id,\n            \"width\": width,\n            \"height\": height,\n            \"annotations\": annotations\n        }\n\n        dataset_dicts.append(record)\n\n    if target_indices is not None:\n        dataset_dicts = [dataset_dicts[i] for i in target_indices]\n\n    return dataset_dicts","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:56.255242Z","iopub.execute_input":"2023-08-06T15:19:56.255946Z","iopub.status.idle":"2023-08-06T15:19:56.267172Z","shell.execute_reply.started":"2023-08-06T15:19:56.255910Z","shell.execute_reply":"2023-08-06T15:19:56.265983Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Register Test Inference data\nDatasetCatalog.register(\n    DATA_REGISTER_TEST,\n    lambda: convert_coco_to_detectron2_format(\n        TEST_IMG_DIR,\n        test_metadata,\n    )\n)\n\n# Set Test data categories\nMetadataCatalog.get(DATA_REGISTER_TEST).set(\n    thing_classes=thing_classes_test\n)\n\ndataset_dicts_test = DatasetCatalog.get(DATA_REGISTER_TEST)\nmetadata_dicts_test = MetadataCatalog.get(DATA_REGISTER_TEST)\n\nprint(\"dicts test size=\", len(dataset_dicts_test))\nprint(\"################\")","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:56.803247Z","iopub.execute_input":"2023-08-06T15:19:56.803635Z","iopub.status.idle":"2023-08-06T15:19:57.603258Z","shell.execute_reply.started":"2023-08-06T15:19:56.803584Z","shell.execute_reply":"2023-08-06T15:19:57.602183Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad84b3bdce644a0cb2a23c5c60599e39"}},"metadata":{}},{"name":"stdout","text":"dicts test size= 13000\n################\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Downloading Model Weight and Configs\n","metadata":{}},{"cell_type":"code","source":"#better to use gdown to fetch from drive\n!gdown 1OkOEy7ZoF7Hmd24wAlvzVb7cEszkcrvk  #model weight\n\n!gdown 1CwIgwAFY4s7Nz-ST7Al2KGL1qtrlIhFx  #config of layoutlmv3","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:19:59.537390Z","iopub.execute_input":"2023-08-06T15:19:59.537772Z","iopub.status.idle":"2023-08-06T15:20:13.424117Z","shell.execute_reply.started":"2023-08-06T15:19:59.537741Z","shell.execute_reply":"2023-08-06T15:20:13.422901Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Downloading...\nFrom (uriginal): https://drive.google.com/uc?id=1OkOEy7ZoF7Hmd24wAlvzVb7cEszkcrvk\nFrom (redirected): https://drive.google.com/uc?id=1OkOEy7ZoF7Hmd24wAlvzVb7cEszkcrvk&confirm=t&uuid=bb66abe8-d35f-4594-b15c-62eb12bc044d\nTo: /kaggle/working/final_train_layoutlmmv3.pth\n100%|████████████████████████████████████████| 564M/564M [00:08<00:00, 64.7MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1CwIgwAFY4s7Nz-ST7Al2KGL1qtrlIhFx\nTo: /kaggle/working/config.json\n100%|██████████████████████████████████████████| 897/897 [00:00<00:00, 4.03MB/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Setting Model Path\n","metadata":{}},{"cell_type":"code","source":"MODEL_PATH=Path(\"/kaggle/working/final_train_layoutlmmv3.pth\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:13.426783Z","iopub.execute_input":"2023-08-06T15:20:13.427450Z","iopub.status.idle":"2023-08-06T15:20:13.432578Z","shell.execute_reply.started":"2023-08-06T15:20:13.427413Z","shell.execute_reply":"2023-08-06T15:20:13.431648Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Setting Test Hyperparameters\n","metadata":{}},{"cell_type":"code","source":"inf_cfg = get_cfg()\n\nadd_vit_config(inf_cfg)\n# Load a config from file\ninf_cfg.merge_from_file(\"/kaggle/working/unilm/layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml\")\ninf_cfg.MODEL.CONFIG_PATH=\"/kaggle/working/config.json\"\ninf_cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\ninf_cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\ninf_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\ninf_cfg.MODEL.DEVICE = \"cuda\"\n\ninf_cfg.DATALOADER.NUM_WORKERS = 1  # lower this if CUDA overflow occurs\ninf_cfg.MODEL.WEIGHTS = str(MODEL_PATH)\nBATCH = 1 # lower this if CUDA overflow occurs\ntest_loader = build_detection_test_loader(inf_cfg, DATA_REGISTER_TEST, batch_size=BATCH)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:13.434509Z","iopub.execute_input":"2023-08-06T15:20:13.435425Z","iopub.status.idle":"2023-08-06T15:20:14.645005Z","shell.execute_reply.started":"2023-08-06T15:20:13.435392Z","shell.execute_reply":"2023-08-06T15:20:14.644081Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09cbf2a09db14ca78fa8d560b24bffd7"}},"metadata":{}},{"name":"stdout","text":"\u001b[32m[08/06 15:20:14 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n| paragraph  | 0            |  text_box  | 0            |   image    | 0            |\n|   table    | 0            |            |              |            |              |\n|   total    | 0            |            |              |            |              |\u001b[0m\n\u001b[32m[08/06 15:20:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[08/06 15:20:14 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[08/06 15:20:14 d2.data.common]: \u001b[0mSerializing 13000 elements to byte tensors and concatenating them all ...\n\u001b[32m[08/06 15:20:14 d2.data.common]: \u001b[0mSerialized dataset takes 2.07 MiB\n","output_type":"stream"}]},{"cell_type":"code","source":"#set acceptance threshold to 0.5\nACCEPTANCE_THRESHOLD = 0.5  # for all categories","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:14.647733Z","iopub.execute_input":"2023-08-06T15:20:14.648155Z","iopub.status.idle":"2023-08-06T15:20:14.652690Z","shell.execute_reply.started":"2023-08-06T15:20:14.648120Z","shell.execute_reply":"2023-08-06T15:20:14.651487Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(f\"#### MODEL: {inf_cfg.MODEL.WEIGHTS} FOR INFERENCE ####\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:14.654100Z","iopub.execute_input":"2023-08-06T15:20:14.654737Z","iopub.status.idle":"2023-08-06T15:20:14.664065Z","shell.execute_reply.started":"2023-08-06T15:20:14.654703Z","shell.execute_reply":"2023-08-06T15:20:14.662973Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"#### MODEL: /kaggle/working/final_train_layoutlmmv3.pth FOR INFERENCE ####\n","output_type":"stream"}]},{"cell_type":"code","source":"def rebuild_model():\n    model = build_model(inf_cfg)\n    _ = DetectionCheckpointer(model).load(inf_cfg.MODEL.WEIGHTS)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:14.665589Z","iopub.execute_input":"2023-08-06T15:20:14.666166Z","iopub.status.idle":"2023-08-06T15:20:14.674145Z","shell.execute_reply.started":"2023-08-06T15:20:14.666134Z","shell.execute_reply":"2023-08-06T15:20:14.673209Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model = rebuild_model()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:14.675726Z","iopub.execute_input":"2023-08-06T15:20:14.676058Z","iopub.status.idle":"2023-08-06T15:20:22.277151Z","shell.execute_reply.started":"2023-08-06T15:20:14.676025Z","shell.execute_reply":"2023-08-06T15:20:22.276109Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"\u001b[32m[08/06 15:20:21 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /kaggle/working/final_train_layoutlmmv3.pth ...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## CUDA Problems\n","metadata":{}},{"cell_type":"code","source":"!export LRU_CACHE_CAPACITY=1\n!export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512'","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:22.279428Z","iopub.execute_input":"2023-08-06T15:20:22.280024Z","iopub.status.idle":"2023-08-06T15:20:24.262099Z","shell.execute_reply.started":"2023-08-06T15:20:22.279987Z","shell.execute_reply":"2023-08-06T15:20:24.260786Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"vars_to_del = [\"trainer\", \"predictor\", \"outputs\"]\n\nfor v in vars_to_del:\n    if v in globals():\n        print(f\"Deleting {v}\")\n        del globals()[v]\n    elif v in locals():\n        print(f\"Deleting {v}\")\n        del locals()[v]","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:24.264920Z","iopub.execute_input":"2023-08-06T15:20:24.265747Z","iopub.status.idle":"2023-08-06T15:20:24.272634Z","shell.execute_reply.started":"2023-08-06T15:20:24.265705Z","shell.execute_reply":"2023-08-06T15:20:24.271480Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Inference Utils\n","metadata":{}},{"cell_type":"code","source":"def rle_encode(mask):\n#     print(mask)\n    pixels = mask.T.flatten()\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    return ' '.join(str(x) for x in rle)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:24.276797Z","iopub.execute_input":"2023-08-06T15:20:24.277103Z","iopub.status.idle":"2023-08-06T15:20:24.287135Z","shell.execute_reply.started":"2023-08-06T15:20:24.277078Z","shell.execute_reply":"2023-08-06T15:20:24.286149Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"@retry_if_cuda_oom\ndef get_masks(prediction):\n    # get masks for each category\n    take = prediction.scores >= ACCEPTANCE_THRESHOLD\n    pred_masks = (prediction.pred_masks[take] != 0)\n    pred_classes = prediction.pred_classes[take]\n  \n    rles = []\n    for cat in range(len(thing_classes_test)):\n        pred_mask = pred_masks[pred_classes == cat]\n        \n        pred_mask = retry_if_cuda_oom(torch.any)(pred_mask, dim=0)\n#         pred_mask = torch.any(pred_mask, dim=0)\n        rles.append(rle_encode(pred_mask.short().to(\"cpu\").numpy()))\n\n    return rles","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:24.288773Z","iopub.execute_input":"2023-08-06T15:20:24.289257Z","iopub.status.idle":"2023-08-06T15:20:24.299505Z","shell.execute_reply.started":"2023-08-06T15:20:24.289223Z","shell.execute_reply":"2023-08-06T15:20:24.298553Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def run_inference(data):\n    results = []\n    with torch.no_grad():\n        outputs = model(data)\n        if torch.cuda.is_available():\n            torch.cuda.synchronize()\n\n        for idx, output in enumerate(outputs):\n            output = output[\"instances\"]\n\n            rles = get_masks(output)\n\n            result = [\n                f\"{data[idx]['image_id']}_{cat},{rles[cat]}\\n\"\n                for cat in range(len(thing_classes_test))\n            ]\n\n            results.extend(result)\n\n        del outputs, output\n\n    return results","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:24.300876Z","iopub.execute_input":"2023-08-06T15:20:24.301602Z","iopub.status.idle":"2023-08-06T15:20:24.310904Z","shell.execute_reply.started":"2023-08-06T15:20:24.301567Z","shell.execute_reply":"2023-08-06T15:20:24.309873Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"## Running Inference on Test Data and Creating Submission File\n","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:27.860101Z","iopub.execute_input":"2023-08-06T15:20:27.860466Z","iopub.status.idle":"2023-08-06T15:20:28.185497Z","shell.execute_reply.started":"2023-08-06T15:20:27.860436Z","shell.execute_reply":"2023-08-06T15:20:28.184449Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"if is_inference:\n    model.eval()\n    submission_file = open(\"submission.csv\", \"w\")\n    submission_file.write(\"Id,Predicted\\n\")\n\n    results: list[str] = []\n    \n    for i, data in enumerate(tqdm(test_loader)):\n        res = run_inference(data)\n        results.extend(res)\n        \n        if i % (500 // BATCH) == 0:\n            print(f\"Inference on batch {i}/{len(test_loader)} done\")\n            submission_file.writelines(results)\n            results = []\n\n    submission_file.writelines(results)\n    submission_file.close()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:20:29.999456Z","iopub.execute_input":"2023-08-06T15:20:30.000168Z","iopub.status.idle":"2023-08-06T15:21:04.835378Z","shell.execute_reply.started":"2023-08-06T15:20:30.000132Z","shell.execute_reply":"2023-08-06T15:21:04.833963Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de4674025db64d879c25447e566fc7a8"}},"metadata":{}},{"name":"stdout","text":"Inference on batch 0/13000 done\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m9\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   \u001b[0mresults: \u001b[96mlist\u001b[0m[\u001b[96mstr\u001b[0m] = []                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m i, data \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(tqdm(test_loader)):                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 9 \u001b[2m│   │   \u001b[0mres = run_inference(data)                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   │   \u001b[0mresults.extend(res)                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m i % (\u001b[94m500\u001b[0m // BATCH) == \u001b[94m0\u001b[0m:                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mrun_inference\u001b[0m:\u001b[94m4\u001b[0m                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mrun_inference\u001b[0m(data):                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[2m│   \u001b[0mresults = []                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 4 \u001b[2m│   │   \u001b[0moutputs = model(data)                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m torch.cuda.is_available():                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   │   │   \u001b[0mtorch.cuda.synchronize()                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/kaggle/working/unilm/layoutlmv3/examples/object_detection/ditod/\u001b[0m\u001b[1;33mrcnn_vl.py\u001b[0m:\u001b[94m55\u001b[0m in \u001b[92mforward\u001b[0m        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2;33m│   │   │   │   \u001b[0m\u001b[33m\"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\", \"pred_keypoints\"\u001b[0m     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 54 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.training:                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 55 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.inference(batched_inputs)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 56 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 57 \u001b[0m\u001b[2m│   │   \u001b[0mimages = \u001b[96mself\u001b[0m.preprocess_image(batched_inputs)                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 58 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33minstances\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m batched_inputs[\u001b[94m0\u001b[0m]:                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/kaggle/working/unilm/layoutlmv3/examples/object_detection/ditod/\u001b[0m\u001b[1;33mrcnn_vl.py\u001b[0m:\u001b[94m117\u001b[0m in \u001b[92minference\u001b[0m     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m detected_instances \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.proposal_generator \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m117 \u001b[2m│   │   │   │   \u001b[0mproposals, _ = \u001b[96mself\u001b[0m.proposal_generator(images, features, \u001b[94mNone\u001b[0m)             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mproposals\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m batched_inputs[\u001b[94m0\u001b[0m]                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mproposals = [x[\u001b[33m\"\u001b[0m\u001b[33mproposals\u001b[0m\u001b[33m\"\u001b[0m].to(\u001b[96mself\u001b[0m.device) \u001b[94mfor\u001b[0m x \u001b[95min\u001b[0m batched_inputs]       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/kaggle/working/detectron2/detectron2/modeling/proposal_generator/\u001b[0m\u001b[1;33mrpn.py\u001b[0m:\u001b[94m452\u001b[0m in \u001b[92mforward\u001b[0m          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m449 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mloss: dict[Tensor] or None\u001b[0m                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m450 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m451 \u001b[0m\u001b[2m│   │   \u001b[0mfeatures = [features[f] \u001b[94mfor\u001b[0m f \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.in_features]                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m452 \u001b[2m│   │   \u001b[0manchors = \u001b[96mself\u001b[0m.anchor_generator(features)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m453 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m454 \u001b[0m\u001b[2m│   │   \u001b[0mpred_objectness_logits, pred_anchor_deltas = \u001b[96mself\u001b[0m.rpn_head(features)               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m455 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Transpose the Hi*Wi*A dimension to the middle:\u001b[0m                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/kaggle/working/detectron2/detectron2/modeling/\u001b[0m\u001b[1;33manchor_generator.py\u001b[0m:\u001b[94m230\u001b[0m in \u001b[92mforward\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2;33m│   │   │   │   \u001b[0m\u001b[33mwhere Hi, Wi are resolution of the feature map divided by anchor stride.\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m228 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m229 \u001b[0m\u001b[2m│   │   \u001b[0mgrid_sizes = [feature_map.shape[-\u001b[94m2\u001b[0m:] \u001b[94mfor\u001b[0m feature_map \u001b[95min\u001b[0m features]                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m230 \u001b[2m│   │   \u001b[0manchors_over_all_feature_maps = \u001b[96mself\u001b[0m._grid_anchors(grid_sizes)                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m231 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m [Boxes(x) \u001b[94mfor\u001b[0m x \u001b[95min\u001b[0m anchors_over_all_feature_maps]                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m232 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m233 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/kaggle/working/detectron2/detectron2/modeling/\u001b[0m\u001b[1;33manchor_generator.py\u001b[0m:\u001b[94m174\u001b[0m in \u001b[92m_grid_anchors\u001b[0m          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# buffers() not supported by torchscript. use named_buffers() instead\u001b[0m              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m172 \u001b[0m\u001b[2m│   │   \u001b[0mbuffers: List[torch.Tensor] = [x[\u001b[94m1\u001b[0m] \u001b[94mfor\u001b[0m x \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.cell_anchors.named_buffers()]    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m size, stride, base_anchors \u001b[95min\u001b[0m \u001b[96mzip\u001b[0m(grid_sizes, \u001b[96mself\u001b[0m.strides, buffers):          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m174 \u001b[2m│   │   │   \u001b[0mshift_x, shift_y = _create_grid_offsets(size, stride, \u001b[96mself\u001b[0m.offset, base_anch   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m│   │   │   \u001b[0mshifts = torch.stack((shift_x, shift_y, shift_x, shift_y), dim=\u001b[94m1\u001b[0m)              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m176 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m│   │   │   \u001b[0manchors.append((shifts.view(-\u001b[94m1\u001b[0m, \u001b[94m1\u001b[0m, \u001b[94m4\u001b[0m) + base_anchors.view(\u001b[94m1\u001b[0m, -\u001b[94m1\u001b[0m, \u001b[94m4\u001b[0m)).reshape   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/kaggle/working/detectron2/detectron2/modeling/\u001b[0m\u001b[1;33manchor_generator.py\u001b[0m:\u001b[94m43\u001b[0m in \u001b[92m_create_grid_offsets\u001b[0m    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   \u001b[0msize: List[\u001b[96mint\u001b[0m], stride: \u001b[96mint\u001b[0m, offset: \u001b[96mfloat\u001b[0m, target_device_tensor: torch.Tensor        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m):                                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2m│   \u001b[0mgrid_height, grid_width = size                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 43 \u001b[2m│   \u001b[0mshifts_x = move_device_like(                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   │   \u001b[0mtorch.arange(offset * stride, grid_width * stride, step=stride, dtype=torch.floa   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   │   \u001b[0mtarget_device_tensor,                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/jit/\u001b[0m\u001b[1;33m_trace.py\u001b[0m:\u001b[94m1220\u001b[0m in \u001b[92mwrapper\u001b[0m                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1217 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mwrapper\u001b[0m(*args, **kwargs):                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1218 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m is_tracing():                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1219 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Not tracing, don't do anything\u001b[0m                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1220 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1221 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1222 \u001b[0m\u001b[2m│   │   \u001b[0mcompiled_fn = script(wrapper.__original_fn)  \u001b[2m# type: ignore[attr-defined]\u001b[0m         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1223 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m compiled_fn(*args, **kwargs)                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/kaggle/working/detectron2/detectron2/layers/\u001b[0m\u001b[1;33mwrappers.py\u001b[0m:\u001b[94m162\u001b[0m in \u001b[92mmove_device_like\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mTracing friendly way to cast tensor to another tensor's device. Device will be treat\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mas constant during tracing, scripting the casting process as whole can workaround th\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m162 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m src.to(dst.device)                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mKeyboardInterrupt\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>results: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>] = []                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i, data <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(tqdm(test_loader)):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 9 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>res = run_inference(data)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>results.extend(res)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> i % (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">500</span> // BATCH) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_inference</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_inference</span>(data):                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>results = []                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 4 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = model(data)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch.cuda.is_available():                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>torch.cuda.synchronize()                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/kaggle/working/unilm/layoutlmv3/examples/object_detection/ditod/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">rcnn_vl.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">55</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 52 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\", \"pred_keypoints\"</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 53 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 54 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 55 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.inference(batched_inputs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 56 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 57 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>images = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.preprocess_image(batched_inputs)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 58 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"instances\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> batched_inputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]:                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/kaggle/working/unilm/layoutlmv3/examples/object_detection/ditod/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">rcnn_vl.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">117</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">inference</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> detected_instances <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.proposal_generator <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>117 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>proposals, _ = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.proposal_generator(images, features, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"proposals\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> batched_inputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>proposals = [x[<span style=\"color: #808000; text-decoration-color: #808000\">\"proposals\"</span>].to(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> x <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> batched_inputs]       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/kaggle/working/detectron2/detectron2/modeling/proposal_generator/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">rpn.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">452</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">449 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">loss: dict[Tensor] or None</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">450 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">451 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>features = [features[f] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> f <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.in_features]                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>452 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>anchors = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.anchor_generator(features)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">453 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">454 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>pred_objectness_logits, pred_anchor_deltas = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.rpn_head(features)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">455 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Transpose the Hi*Wi*A dimension to the middle:</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/kaggle/working/detectron2/detectron2/modeling/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">anchor_generator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">230</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">where Hi, Wi are resolution of the feature map divided by anchor stride.</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">229 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>grid_sizes = [feature_map.shape[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>:] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> feature_map <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> features]                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>230 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>anchors_over_all_feature_maps = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._grid_anchors(grid_sizes)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">231 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> [Boxes(x) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> x <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> anchors_over_all_feature_maps]                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">232 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">233 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/kaggle/working/detectron2/detectron2/modeling/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">anchor_generator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">174</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_grid_anchors</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># buffers() not supported by torchscript. use named_buffers() instead</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">172 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>buffers: List[torch.Tensor] = [x[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> x <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cell_anchors.named_buffers()]    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> size, stride, base_anchors <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">zip</span>(grid_sizes, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strides, buffers):          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>174 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>shift_x, shift_y = _create_grid_offsets(size, stride, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.offset, base_anch   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>shifts = torch.stack((shift_x, shift_y, shift_x, shift_y), dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">176 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>anchors.append((shifts.view(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>) + base_anchors.view(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>)).reshape   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/kaggle/working/detectron2/detectron2/modeling/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">anchor_generator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">43</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_create_grid_offsets</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 40 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>size: List[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>], stride: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>, offset: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">float</span>, target_device_tensor: torch.Tensor        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 </span>):                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 42 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>grid_height, grid_width = size                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 43 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>shifts_x = move_device_like(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 44 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.arange(offset * stride, grid_width * stride, step=stride, dtype=torch.floa   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>target_device_tensor,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 46 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>)                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/jit/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_trace.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1220</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1217 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>(*args, **kwargs):                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1218 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> is_tracing():                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1219 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Not tracing, don't do anything</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1220 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*args, **kwargs)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1221 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1222 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>compiled_fn = script(wrapper.__original_fn)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[attr-defined]</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1223 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> compiled_fn(*args, **kwargs)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/kaggle/working/detectron2/detectron2/layers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">wrappers.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">162</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">move_device_like</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">Tracing friendly way to cast tensor to another tensor's device. Device will be treat</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">as constant during tracing, scripting the casting process as whole can workaround th</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>162 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> src.to(dst.device)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"if Path(\"submission.csv\").exists:\n    display(FileLink(\"submission.csv\"))","metadata":{},"execution_count":null,"outputs":[]}]}